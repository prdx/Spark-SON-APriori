mvn clean package
[INFO] Scanning for projects...
[INFO] 
[INFO] ------------------------------------------------------------------------
[INFO] Building project 1.0
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ project ---
[INFO] Deleting /home/jay/CS6240-Project/target
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ project ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /home/jay/CS6240-Project/src/main/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ project ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- scala-maven-plugin:3.3.1:compile (default) @ project ---
[WARNING]  Expected all dependencies to require Scala version: 2.11.12
[WARNING]  cs6240:project:1.0 requires scala version: 2.11.12
[WARNING]  com.twitter:chill_2.11:0.8.4 requires scala version: 2.11.8
[WARNING] Multiple versions of scala libraries detected!
[INFO] /home/jay/CS6240-Project/src/main/scala:-1: info: compiling
[INFO] Compiling 3 source files to /home/jay/CS6240-Project/target/classes at 1553901866503
[INFO] prepare-compile in 0 s
[INFO] compile in 62 s
[INFO] 
[INFO] --- maven-resources-plugin:2.6:testResources (default-testResources) @ project ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] skip non existing resourceDirectory /home/jay/CS6240-Project/src/test/resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:testCompile (default-testCompile) @ project ---
[INFO] No sources to compile
[INFO] 
[INFO] --- maven-surefire-plugin:2.12.4:test (default-test) @ project ---
[INFO] No tests to run.
[INFO] 
[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ project ---
[INFO] Building jar: /home/jay/CS6240-Project/target/project-1.0.jar
[INFO] 
[INFO] --- maven-shade-plugin:3.1.0:shade (default) @ project ---
[INFO] Replacing original artifact with shaded artifact.
[INFO] Replacing /home/jay/CS6240-Project/target/project-1.0.jar with /home/jay/CS6240-Project/target/project-1.0-shaded.jar
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 01:42 min
[INFO] Finished at: 2019-03-29T19:25:34-04:00
[INFO] Final Memory: 31M/455M
[INFO] ------------------------------------------------------------------------
cp target/project-1.0.jar project.jar
rm -rf output
spark-submit --class project.ProjectImpl --master local[4] --name "Project" project.jar input output 0.9
2019-03-29 19:25:45 WARN  Utils:66 - Your hostname, jay-VirtualBox resolves to a loopback address: 127.0.1.1; using 10.0.2.15 instead (on interface enp0s3)
2019-03-29 19:25:45 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2019-03-29 19:25:49 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-03-29 19:25:51 INFO  SparkContext:54 - Running Spark version 2.4.0
2019-03-29 19:25:51 INFO  SparkContext:54 - Submitted application: Project - APriori
2019-03-29 19:25:52 INFO  SecurityManager:54 - Changing view acls to: jay
2019-03-29 19:25:52 INFO  SecurityManager:54 - Changing modify acls to: jay
2019-03-29 19:25:52 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-03-29 19:25:52 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-03-29 19:25:52 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(jay); groups with view permissions: Set(); users  with modify permissions: Set(jay); groups with modify permissions: Set()
2019-03-29 19:25:53 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 35985.
2019-03-29 19:25:54 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-03-29 19:25:54 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-03-29 19:25:54 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-03-29 19:25:54 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-03-29 19:25:54 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-98968634-f987-4499-adb3-c0a5549ecb13
2019-03-29 19:25:54 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-03-29 19:25:54 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-03-29 19:25:55 INFO  log:192 - Logging initialized @16559ms
2019-03-29 19:25:55 INFO  Server:351 - jetty-9.3.z-SNAPSHOT, build timestamp: unknown, git hash: unknown
2019-03-29 19:25:56 INFO  Server:419 - Started @17094ms
2019-03-29 19:25:56 INFO  AbstractConnector:278 - Started ServerConnector@5739325a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-29 19:25:56 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@49a64d82{/jobs,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2d35442b{/jobs/json,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27f9e982{/jobs/job,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d3d232{/jobs/job/json,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30c0ccff{/stages,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@581d969c{/stages/json,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22db8f4{/stages/stage,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29caf222{/stages/stage/json,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46cf05f7{/stages/pool,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5851bd4f{/stages/pool/json,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cd1ac19{/storage,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f40a43{/storage/json,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3caa4757{/storage/rdd,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@69c43e48{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1804f60d{/environment,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3a80515c{/environment/json,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@547e29a4{/executors,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1c807b1d{/executors/json,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@238b521e{/executors/threadDump,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1b39fd82{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3e2fc448{/static,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5167268{/,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1cfd1875{/api,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6ebd78d1{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@436390f4{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-03-29 19:25:56 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://10.0.2.15:4040
2019-03-29 19:25:57 INFO  SparkContext:54 - Added JAR file:/home/jay/CS6240-Project/project.jar at spark://10.0.2.15:35985/jars/project.jar with timestamp 1553901957114
2019-03-29 19:25:57 INFO  Executor:54 - Starting executor ID driver on host localhost
2019-03-29 19:25:58 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 37389.
2019-03-29 19:25:58 INFO  NettyBlockTransferService:54 - Server created on 10.0.2.15:37389
2019-03-29 19:25:58 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-03-29 19:25:58 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 10.0.2.15, 37389, None)
2019-03-29 19:25:58 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 10.0.2.15:37389 with 366.3 MB RAM, BlockManagerId(driver, 10.0.2.15, 37389, None)
2019-03-29 19:25:58 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 10.0.2.15, 37389, None)
2019-03-29 19:25:58 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 10.0.2.15, 37389, None)
2019-03-29 19:25:59 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5f84abe8{/metrics/json,null,AVAILABLE,@Spark}
2019-03-29 19:26:05 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 394.1 KB, free 365.9 MB)
2019-03-29 19:26:07 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 35.8 KB, free 365.9 MB)
2019-03-29 19:26:07 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 10.0.2.15:37389 (size: 35.8 KB, free: 366.3 MB)
2019-03-29 19:26:07 INFO  SparkContext:54 - Created broadcast 0 from textFile at ProjectImpl.scala:19
2019-03-29 19:26:08 INFO  FileInputFormat:256 - Total input files to process : 1
2019-03-29 19:26:08 INFO  deprecation:1297 - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2019-03-29 19:26:08 INFO  HadoopMapRedCommitProtocol:54 - Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
2019-03-29 19:26:08 INFO  FileOutputCommitter:123 - File Output Committer Algorithm version is 1
2019-03-29 19:26:08 INFO  FileOutputCommitter:138 - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-03-29 19:26:09 INFO  SparkContext:54 - Starting job: runJob at SparkHadoopWriter.scala:78
2019-03-29 19:26:09 INFO  DAGScheduler:54 - Registering RDD 2 (map at ProjectImpl.scala:28)
2019-03-29 19:26:09 INFO  DAGScheduler:54 - Got job 0 (runJob at SparkHadoopWriter.scala:78) with 2 output partitions
2019-03-29 19:26:09 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (runJob at SparkHadoopWriter.scala:78)
2019-03-29 19:26:09 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 0)
2019-03-29 19:26:09 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 0)
2019-03-29 19:26:09 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[2] at map at ProjectImpl.scala:28), which has no missing parents
2019-03-29 19:26:09 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 5.6 KB, free 365.9 MB)
2019-03-29 19:26:09 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 3.1 KB, free 365.9 MB)
2019-03-29 19:26:09 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 10.0.2.15:37389 (size: 3.1 KB, free: 366.3 MB)
2019-03-29 19:26:09 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1161
2019-03-29 19:26:10 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[2] at map at ProjectImpl.scala:28) (first 15 tasks are for partitions Vector(0, 1))
2019-03-29 19:26:10 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 2 tasks
2019-03-29 19:26:10 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 7892 bytes)
2019-03-29 19:26:10 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, localhost, executor driver, partition 1, PROCESS_LOCAL, 7892 bytes)
2019-03-29 19:26:10 INFO  Executor:54 - Running task 1.0 in stage 0.0 (TID 1)
2019-03-29 19:26:10 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)
2019-03-29 19:26:10 INFO  Executor:54 - Fetching spark://10.0.2.15:35985/jars/project.jar with timestamp 1553901957114
2019-03-29 19:26:10 INFO  TransportClientFactory:267 - Successfully created connection to /10.0.2.15:35985 after 222 ms (0 ms spent in bootstraps)
2019-03-29 19:26:11 INFO  Utils:54 - Fetching spark://10.0.2.15:35985/jars/project.jar to /tmp/spark-6496910f-ef5f-49d2-aed4-cab7e089456b/userFiles-232e6184-4ffc-462f-b456-1e1e71c35d2d/fetchFileTemp3951159894168471360.tmp
2019-03-29 19:26:11 INFO  Executor:54 - Adding file:/tmp/spark-6496910f-ef5f-49d2-aed4-cab7e089456b/userFiles-232e6184-4ffc-462f-b456-1e1e71c35d2d/project.jar to class loader
2019-03-29 19:26:11 INFO  HadoopRDD:54 - Input split: file:/home/jay/CS6240-Project/input/inp.txt:31+32
2019-03-29 19:26:11 INFO  HadoopRDD:54 - Input split: file:/home/jay/CS6240-Project/input/inp.txt:0+31
2019-03-29 19:26:14 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1065 bytes result sent to driver
2019-03-29 19:26:14 INFO  Executor:54 - Finished task 1.0 in stage 0.0 (TID 1). 1065 bytes result sent to driver
2019-03-29 19:26:14 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 3764 ms on localhost (executor driver) (1/2)
2019-03-29 19:26:14 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 3660 ms on localhost (executor driver) (2/2)
2019-03-29 19:26:14 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-03-29 19:26:14 INFO  DAGScheduler:54 - ShuffleMapStage 0 (map at ProjectImpl.scala:28) finished in 4.593 s
2019-03-29 19:26:14 INFO  DAGScheduler:54 - looking for newly runnable stages
2019-03-29 19:26:14 INFO  DAGScheduler:54 - running: Set()
2019-03-29 19:26:14 INFO  DAGScheduler:54 - waiting: Set(ResultStage 1)
2019-03-29 19:26:14 INFO  DAGScheduler:54 - failed: Set()
2019-03-29 19:26:14 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[6] at saveAsTextFile at ProjectImpl.scala:30), which has no missing parents
2019-03-29 19:26:14 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 110.1 KB, free 365.8 MB)
2019-03-29 19:26:14 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 40.6 KB, free 365.7 MB)
2019-03-29 19:26:14 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 10.0.2.15:37389 (size: 40.6 KB, free: 366.2 MB)
2019-03-29 19:26:14 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2019-03-29 19:26:14 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[6] at saveAsTextFile at ProjectImpl.scala:30) (first 15 tasks are for partitions Vector(0, 1))
2019-03-29 19:26:14 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 2 tasks
2019-03-29 19:26:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 2, localhost, executor driver, partition 0, ANY, 7662 bytes)
2019-03-29 19:26:14 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 3, localhost, executor driver, partition 1, ANY, 7662 bytes)
2019-03-29 19:26:14 INFO  Executor:54 - Running task 1.0 in stage 1.0 (TID 3)
2019-03-29 19:26:14 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 2)
2019-03-29 19:26:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 1 non-empty blocks including 1 local blocks and 0 remote blocks
2019-03-29 19:26:15 INFO  ShuffleBlockFetcherIterator:54 - Getting 2 non-empty blocks including 2 local blocks and 0 remote blocks
2019-03-29 19:26:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 45 ms
2019-03-29 19:26:15 INFO  ShuffleBlockFetcherIterator:54 - Started 0 remote fetches in 44 ms
2019-03-29 19:26:15 INFO  HadoopMapRedCommitProtocol:54 - Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
2019-03-29 19:26:15 INFO  HadoopMapRedCommitProtocol:54 - Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
2019-03-29 19:26:15 INFO  FileOutputCommitter:123 - File Output Committer Algorithm version is 1
2019-03-29 19:26:15 INFO  FileOutputCommitter:138 - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-03-29 19:26:15 INFO  FileOutputCommitter:123 - File Output Committer Algorithm version is 1
2019-03-29 19:26:15 INFO  FileOutputCommitter:138 - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-03-29 19:26:15 INFO  FileOutputCommitter:582 - Saved output of task 'attempt_20190329192608_0006_m_000000_0' to file:/home/jay/CS6240-Project/output/_temporary/0/task_20190329192608_0006_m_000000
2019-03-29 19:26:15 INFO  FileOutputCommitter:582 - Saved output of task 'attempt_20190329192608_0006_m_000001_0' to file:/home/jay/CS6240-Project/output/_temporary/0/task_20190329192608_0006_m_000001
2019-03-29 19:26:15 INFO  SparkHadoopMapRedUtil:54 - attempt_20190329192608_0006_m_000000_0: Committed
2019-03-29 19:26:15 INFO  SparkHadoopMapRedUtil:54 - attempt_20190329192608_0006_m_000001_0: Committed
2019-03-29 19:26:15 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 2). 1502 bytes result sent to driver
2019-03-29 19:26:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 2) in 1270 ms on localhost (executor driver) (1/2)
2019-03-29 19:26:15 INFO  Executor:54 - Finished task 1.0 in stage 1.0 (TID 3). 1502 bytes result sent to driver
2019-03-29 19:26:15 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 3) in 1318 ms on localhost (executor driver) (2/2)
2019-03-29 19:26:15 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2019-03-29 19:26:15 INFO  DAGScheduler:54 - ResultStage 1 (runJob at SparkHadoopWriter.scala:78) finished in 1.600 s
2019-03-29 19:26:16 INFO  DAGScheduler:54 - Job 0 finished: runJob at SparkHadoopWriter.scala:78, took 6.856291 s
2019-03-29 19:26:16 INFO  SparkHadoopWriter:54 - Job job_20190329192608_0006 committed.
2019-03-29 19:26:16 INFO  SparkContext:54 - Invoking stop() from shutdown hook
2019-03-29 19:26:16 INFO  AbstractConnector:318 - Stopped Spark@5739325a{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2019-03-29 19:26:16 INFO  SparkUI:54 - Stopped Spark web UI at http://10.0.2.15:4040
2019-03-29 19:26:16 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-03-29 19:26:16 INFO  MemoryStore:54 - MemoryStore cleared
2019-03-29 19:26:16 INFO  BlockManager:54 - BlockManager stopped
2019-03-29 19:26:16 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-03-29 19:26:16 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-03-29 19:26:16 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-03-29 19:26:16 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-03-29 19:26:16 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-057fb4a7-4cc6-4b01-b0e7-53b0d12806d0
2019-03-29 19:26:16 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-6496910f-ef5f-49d2-aed4-cab7e089456b

